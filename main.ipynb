{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "uwu2wY-gT90a"
      },
      "outputs": [],
      "source": [
        "from model import Actor, Critic, DRRAveStateRepresentation, PMF\n",
        "from learn import DRRTrainer\n",
        "from utils.general import csv_plot\n",
        "import torch\n",
        "import pickle\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import datetime\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        " \n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJgM7skZmj2H",
        "outputId": "d98cdd53-85c0-4120-ff40-52dd6d994737"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initializing DRR Framework ----------------------------------------------------------------------------\n",
            "Using CPU\n",
            "Seeds initialized\n",
            "int64\n",
            "[[         0 1531001351          0 ...    1575913         33      80739]\n",
            " [         1 1325604498          0 ...     808602         10      19425]\n",
            " [         0 1391632230          0 ...     301895       1332      83879]\n",
            " ...\n",
            " [         0 1577678190          0 ...    1578206        326      65728]\n",
            " [         1 1642618767          0 ...    1117070        281      67627]\n",
            " [         0 1514933447          3 ...     227711       1868      75424]]\n",
            "Data imported, shuffled, and split into Train/Test, ratio= 0.8\n",
            "Debug: train_data tensor([[         1, 1546693532,          0,  ...,    1404279,          7,\n",
            "             118750],\n",
            "        [         0, 1396451829,          0,  ...,     690079,          5,\n",
            "              30670],\n",
            "        [         1, 1494989962,          0,  ...,     316522,         23,\n",
            "             130056],\n",
            "        ...,\n",
            "        [         1, 1625455155,          0,  ...,     371174,          6,\n",
            "              26170],\n",
            "        [         1, 1456430287,          0,  ...,    1889048,          2,\n",
            "              81183],\n",
            "        [         1, 1518280008,          0,  ...,     505300,          4,\n",
            "              39454]])\n",
            "Train data shape:  torch.Size([5592153, 8])\n",
            "Test data shape:  torch.Size([1398039, 8])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_4961/913719725.py:106: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  reward_function.load_state_dict(torch.load(config.path_to_trained_pmf))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initialized PMF, imported weights, created reward_function\n",
            "Extracted user and item embeddings from PMF\n",
            "User embeddings shape:  torch.Size([1987843, 100])\n",
            "Item embeddings shape:  torch.Size([150346, 100])\n",
            "Initializing DRRTrainer -------------------------------------------------------------------------------\n",
            "CUDA Device ID:  0\n",
            "NVIDIA GeForce RTX 3050 Ti Laptop GPU\n",
            "CUDA Memory Allocated:  0\n",
            "CUDA Memory Reserved:  0.0 GB\n",
            "Current PyTorch Device:  cpu\n",
            "Data dimensions extracted\n",
            "Models initialized\n",
            "Model weights initialized, copied to target\n",
            "Optimizers initialized\n"
          ]
        }
      ],
      "source": [
        "class config():\n",
        "    output_path = 'results/' + datetime.datetime.now().strftime('%y%m%d') + '/'\n",
        "    if not os.path.exists(output_path):\n",
        "        os.makedirs(output_path)\n",
        "    plot_dir = output_path + 'rewards.pdf'\n",
        " \n",
        "    train_actor_loss_data_dir = output_path + 'train_actor_loss_data.npy'\n",
        "    train_critic_loss_data_dir = output_path + 'train_critic_loss_data.npy'\n",
        "    train_mean_reward_data_dir = output_path + 'train_mean_reward_data.npy'\n",
        " \n",
        "    train_actor_loss_plot_dir = output_path + 'train_actor_loss.png'\n",
        "    train_critic_loss_plot_dir = output_path + 'train_critic_loss.png'\n",
        "    train_mean_reward_plot_dir = output_path + 'train_mean_reward.png'\n",
        " \n",
        "    trained_models_dir = 'trained/'\n",
        " \n",
        "    actor_model_trained = trained_models_dir + 'actor_net.weights'\n",
        "    critic_model_trained = trained_models_dir + 'critic_net.weights'\n",
        "    state_rep_model_trained = trained_models_dir + 'state_rep_net.weights'\n",
        " \n",
        "    actor_model_dir = output_path + 'actor_net.weights'\n",
        "    critic_model_dir = output_path + 'critic_net.weights'\n",
        "    state_rep_model_dir = output_path + 'state_rep_net.weights'\n",
        " \n",
        "    csv_dir = output_path + 'log.csv'\n",
        " \n",
        "    path_to_trained_pmf = trained_models_dir + 'trained_pmf.pt'\n",
        " \n",
        "    # hyperparams\n",
        "    batch_size = 64\n",
        "    gamma = 0.9\n",
        "    replay_buffer_size = 100000\n",
        "    history_buffer_size = 5\n",
        "    learning_start = 5000\n",
        "    learning_freq = 1\n",
        "    lr_state_rep = 0.001\n",
        "    lr_actor = 0.0001\n",
        "    lr_critic = 0.001\n",
        "    eps_start = 1\n",
        "    eps = 0.1\n",
        "    eps_steps = 10000\n",
        "    eps_eval = 0.1\n",
        "    tau = 0.01 # inital 0.001\n",
        "    beta = 0.4\n",
        "    prob_alpha = 0.3\n",
        "    max_timesteps_train = 260000\n",
        "    max_epochs_offline = 500\n",
        "    max_timesteps_online = 20000\n",
        "    embedding_feature_size = 100\n",
        "    episode_length = 10\n",
        "    train_ratio = 0.8\n",
        "    weight_decay = 0.01\n",
        "    clip_val = 1.0\n",
        "    log_freq = 100\n",
        "    saving_freq = 1000\n",
        "    zero_reward = False\n",
        " \n",
        "    enable_cuda = False\n",
        " \n",
        "def seed_all(cuda, seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if cuda:\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.manual_seed(seed=seed)\n",
        " \n",
        "print(\"Initializing DRR Framework ----------------------------------------------------------------------------\")\n",
        " \n",
        "# Get CUDA device if available\n",
        "cuda = True if config.enable_cuda and torch.cuda.is_available() else False\n",
        "print(\"Using CUDA\") if cuda else print(\"Using CPU\")\n",
        " \n",
        "# Init seeds\n",
        "seed_all(cuda, 0)\n",
        "print(\"Seeds initialized\")\n",
        " \n",
        "# Grab models\n",
        "actor_function = Actor\n",
        "critic_function = Critic\n",
        "state_rep_function = DRRAveStateRepresentation\n",
        " \n",
        "# Import Data\n",
        "users = pickle.load(open('dataset/user_id_to_num.pkl', 'rb'))\n",
        "items = pickle.load(open('dataset/rest_id_to_num.pkl', 'rb'))\n",
        "data = np.load('dataset/data.npy')\n",
        "\n",
        "# Normalize rewards to [-1, 1]\n",
        "data[:, 0] = data[:, 0].astype(float)\n",
        "print(data.dtype)\n",
        "data[:, 0] = 0.5 * (data[:, 0] - 3)\n",
        "print(data)\n",
        " \n",
        "np.random.shuffle(data)\n",
        "train_data = torch.from_numpy(data[:int(config.train_ratio * data.shape[0])])\n",
        "test_data = torch.from_numpy(data[int(config.train_ratio * data.shape[0]):])\n",
        "print(\"Data imported, shuffled, and split into Train/Test, ratio=\", config.train_ratio)\n",
        "print(\"Debug: train_data\", train_data)\n",
        "print(\"Train data shape: \", train_data.shape)\n",
        "print(\"Test data shape: \", test_data.shape)\n",
        " \n",
        "# Create and load PMF function for rewards and embeddings\n",
        "n_users = len(users)\n",
        "n_items = len(items)\n",
        "reward_function = PMF(n_users, n_items, config.embedding_feature_size, is_sparse=False, enable_cuda=cuda)\n",
        "reward_function.load_state_dict(torch.load(config.path_to_trained_pmf))\n",
        " \n",
        "# Freeze all the parameters in the network\n",
        "for param in reward_function.parameters():\n",
        "    param.requires_grad = False\n",
        "print(\"Initialized PMF, imported weights, created reward_function\")\n",
        " \n",
        "# Extract embeddings\n",
        "user_embeddings = reward_function.user_embeddings.weight.data\n",
        "item_embeddings = reward_function.item_embeddings.weight.data\n",
        "print(\"Extracted user and item embeddings from PMF\")\n",
        "print(\"User embeddings shape: \", user_embeddings.shape)\n",
        "print(\"Item embeddings shape: \", item_embeddings.shape)\n",
        " \n",
        "# Init trainer\n",
        "print(\"Initializing DRRTrainer -------------------------------------------------------------------------------\")\n",
        "trainer = DRRTrainer(config,\n",
        "                      actor_function,\n",
        "                      critic_function,\n",
        "                      state_rep_function,\n",
        "                      reward_function,\n",
        "                      users,\n",
        "                      items,\n",
        "                      train_data,\n",
        "                      test_data,\n",
        "                      user_embeddings,\n",
        "                      item_embeddings,\n",
        "                      cuda\n",
        "                      )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting DRRTrainer.learn() ---------------------------------------------------------------------------\n",
            "Debug: start learning\n",
            "tensor([[5.0000e-01, 1.3127e+09, 2.0000e+00, 1.0000e+00, 4.0000e+00, 1.5934e+06,\n",
            "         1.5000e+01, 8.0878e+04],\n",
            "        [5.0000e-01, 1.3200e+09, 0.0000e+00, 1.0000e+00, 1.0000e+00, 1.5934e+06,\n",
            "         1.5000e+01, 6.0695e+04],\n",
            "        [5.0000e-01, 1.5010e+09, 1.0000e+00, 0.0000e+00, 1.0000e+00, 1.5934e+06,\n",
            "         1.5000e+01, 1.7142e+04],\n",
            "        [1.0000e+00, 1.5287e+09, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5934e+06,\n",
            "         1.5000e+01, 4.8691e+04],\n",
            "        [1.0000e+00, 1.5322e+09, 0.0000e+00, 1.0000e+00, 0.0000e+00, 1.5934e+06,\n",
            "         1.5000e+01, 6.3109e+04],\n",
            "        [1.0000e+00, 1.5788e+09, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5934e+06,\n",
            "         1.5000e+01, 2.6781e+04]], dtype=torch.float64)\n"
          ]
        },
        {
          "ename": "IndexError",
          "evalue": "tensors used as indices must be long, int, byte or bool tensors",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting DRRTrainer.learn() ---------------------------------------------------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m actor_losses, critic_losses, epi_avg_rewards \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Tori/DRL-based-Recommendation/learn.py:184\u001b[0m, in \u001b[0;36mDRRTrainer.learn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    182\u001b[0m ignored_items \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mhistory_buffer_size):\n\u001b[0;32m--> 184\u001b[0m     emb \u001b[38;5;241m=\u001b[39m \u001b[43mcandidate_items\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpos_user_reviews\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    185\u001b[0m     history_buffer\u001b[38;5;241m.\u001b[39mpush(emb\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mclone())\n\u001b[1;32m    187\u001b[0m \u001b[38;5;66;03m# Initialize rewards tracker\u001b[39;00m\n",
            "\u001b[0;31mIndexError\u001b[0m: tensors used as indices must be long, int, byte or bool tensors"
          ]
        }
      ],
      "source": [
        "# Train\n",
        "print(\"Starting DRRTrainer.learn() ---------------------------------------------------------------------------\")\n",
        "actor_losses, critic_losses, epi_avg_rewards = trainer.learn()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "e7WsofyYJs4A"
      },
      "outputs": [],
      "source": [
        "# Change to newest trained data directories\n",
        "config.trained_models_dir = config.output_path\n",
        "output_path = config.output_path\n",
        "# config.trained_models_dir = \"results/210419-181221/\"\n",
        "# output_path = \"results/210419-181221/\"\n",
        "\n",
        "train_actor_loss_data_dir = output_path + 'train_actor_loss_data.npy'\n",
        "train_critic_loss_data_dir = output_path + 'train_critic_loss_data.npy'\n",
        "train_mean_reward_data_dir = output_path + 'train_mean_reward_data.npy'\n",
        "\n",
        "config.actor_model_trained = config.trained_models_dir + 'actor_net.weights'\n",
        "config.critic_model_trained = config.trained_models_dir + 'critic_net.weights'\n",
        "config.state_rep_model_trained = config.trained_models_dir + 'state_rep_net.weights'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVrzFMYyPot7",
        "outputId": "cc62d7f4-c9fa-4448-9b62-227bd062672b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tsmoothie in /home/tori/miniconda3/envs/drl-based-recommendation/lib/python3.10/site-packages (1.0.5)\n",
            "Requirement already satisfied: numpy in /home/tori/.local/lib/python3.10/site-packages (from tsmoothie) (2.1.1)\n",
            "Requirement already satisfied: scipy in /home/tori/miniconda3/envs/drl-based-recommendation/lib/python3.10/site-packages (from tsmoothie) (1.14.1)\n",
            "Requirement already satisfied: simdkalman in /home/tori/miniconda3/envs/drl-based-recommendation/lib/python3.10/site-packages (from tsmoothie) (1.0.4)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install tsmoothie\n",
        "\n",
        "def noiseless_plot(y, title, ylabel, save_loc):\n",
        "  # operate smoothing\n",
        "  smoother = ConvolutionSmoother(window_len=1000, window_type='ones')\n",
        "  smoother.smooth(y)\n",
        "\n",
        "  # generate intervals\n",
        "  low, up = smoother.get_intervals('sigma_interval', n_sigma=3)\n",
        "\n",
        "  # plot the smoothed timeseries with intervals\n",
        "  plt.close()\n",
        "  plt.figure(figsize=(11,6))\n",
        "  plt.xlabel(\"Epoch\") \n",
        "  plt.ylabel(ylabel)\n",
        "  plt.title(title)\n",
        "  plt.plot(smoother.data[0], color='orange')\n",
        "  plt.plot(smoother.smooth_data[0], linewidth=3, color='blue')\n",
        "  plt.fill_between(range(len(smoother.data[0])), low[0], up[0], alpha=0.3)\n",
        "  plt.savefig(save_loc)\n",
        "  plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Js_AsydTL4rX"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'smoother' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[29], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m critic_losses \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(train_critic_loss_data_dir)\n\u001b[1;32m      6\u001b[0m epi_avg_rewards \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(train_mean_reward_data_dir)\n\u001b[0;32m----> 8\u001b[0m \u001b[43mnoiseless_plot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactor_losses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m               \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mActor Loss (Train)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m               \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mActor Loss (Train)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m               \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain_actor_loss_smooth.png\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m noiseless_plot(critic_losses, \n\u001b[1;32m     14\u001b[0m                \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCritic Loss (Train)\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m     15\u001b[0m                \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCritic Loss (Train)\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m     16\u001b[0m                output_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_critic_loss_smooth.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m noiseless_plot(epi_avg_rewards, \n\u001b[1;32m     19\u001b[0m                \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean Reward (Train)\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m     20\u001b[0m                \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean Reward (Train)\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m     21\u001b[0m                output_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_mean_reward_smooth.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "Cell \u001b[0;32mIn[28], line 9\u001b[0m, in \u001b[0;36mnoiseless_plot\u001b[0;34m(y, title, ylabel, save_loc)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnoiseless_plot\u001b[39m(y, title, ylabel, save_loc):\n\u001b[1;32m      4\u001b[0m   \u001b[38;5;66;03m# operate smoothing\u001b[39;00m\n\u001b[1;32m      5\u001b[0m   \u001b[38;5;66;03m# smoother = ConvolutionSmoother(window_len=1000, window_type='ones')\u001b[39;00m\n\u001b[1;32m      6\u001b[0m   \u001b[38;5;66;03m# smoother.smooth(y)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \n\u001b[1;32m      8\u001b[0m   \u001b[38;5;66;03m# generate intervals\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m   low, up \u001b[38;5;241m=\u001b[39m \u001b[43msmoother\u001b[49m\u001b[38;5;241m.\u001b[39mget_intervals(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigma_interval\u001b[39m\u001b[38;5;124m'\u001b[39m, n_sigma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     11\u001b[0m   \u001b[38;5;66;03m# plot the smoothed timeseries with intervals\u001b[39;00m\n\u001b[1;32m     12\u001b[0m   plt\u001b[38;5;241m.\u001b[39mclose()\n",
            "\u001b[0;31mNameError\u001b[0m: name 'smoother' is not defined"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from tsmoothie.smoother import *\n",
        "\n",
        "actor_losses = np.load(train_actor_loss_data_dir)\n",
        "critic_losses = np.load(train_critic_loss_data_dir)\n",
        "epi_avg_rewards = np.load(train_mean_reward_data_dir)\n",
        "\n",
        "noiseless_plot(actor_losses, \n",
        "               \"Actor Loss (Train)\", \n",
        "               \"Actor Loss (Train)\", \n",
        "               output_path + \"train_actor_loss_smooth.png\")\n",
        "               \n",
        "noiseless_plot(critic_losses, \n",
        "               \"Critic Loss (Train)\", \n",
        "               \"Critic Loss (Train)\", \n",
        "               output_path + \"train_critic_loss_smooth.png\")\n",
        "\n",
        "noiseless_plot(epi_avg_rewards, \n",
        "               \"Mean Reward (Train)\", \n",
        "               \"Mean Reward (Train)\", \n",
        "               output_path + \"train_mean_reward_smooth.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpdq8n7aQFag"
      },
      "source": [
        "Save hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "V0TuQQlwYDhM"
      },
      "outputs": [],
      "source": [
        "sourceFile = open(output_path + \"hyperparams.txt\", 'w')\n",
        "print(config.__dict__, file = sourceFile)\n",
        "sourceFile.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCzuHAUiWpTO"
      },
      "source": [
        "**Run** Offline and Online evaluations, save scores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "emn4GkW1UP6S"
      },
      "outputs": [],
      "source": [
        "T_precisions = [5, 10, 15, 20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DUP2Ryq1Zeo6",
        "outputId": "8cefc22a-41ce-46a8-8509-15471e56e065"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/tori/Tori/DRL-based-Recommendation/learn.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  self.actor_net.load_state_dict(torch.load(self.config.actor_model_trained))\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'results/241012-14/state_rep_net.weights'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[13], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m pmf_Ts \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m20\u001b[39m):\n\u001b[1;32m      7\u001b[0m   \u001b[38;5;66;03m# Evaluate\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m   avg_precision \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moffline_pmf_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mT_precision\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m   \u001b[38;5;66;03m# Append to list\u001b[39;00m\n\u001b[1;32m     11\u001b[0m   pmf_Ts\u001b[38;5;241m.\u001b[39mappend(avg_precision)\n",
            "File \u001b[0;32m~/Tori/DRL-based-Recommendation/learn.py:779\u001b[0m, in \u001b[0;36moffline_pmf_evaluate\u001b[0;34m(self, T)\u001b[0m\n\u001b[1;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
            "File \u001b[0;32m~/Tori/DRL-based-Recommendation/learn.py:125\u001b[0m, in \u001b[0;36mload_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_parameters\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate_rep_net\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mstate_rep_model_trained))\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactor_net\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mactor_model_trained))\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcritic_net\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mcritic_model_trained))\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_actor_net\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactor_net\u001b[38;5;241m.\u001b[39mstate_dict())\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/serialization.py:1065\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m   1063\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m-> 1065\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m   1066\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m   1067\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1068\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1069\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1070\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/serialization.py:468\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 468\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    470\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/serialization.py:449\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'results/241012-14/state_rep_net.weights'"
          ]
        }
      ],
      "source": [
        "# Offline evaluate\n",
        "\n",
        "# PMF\n",
        "for T_precision in T_precisions:\n",
        "  pmf_Ts = []\n",
        "  for i in range(20):\n",
        "    # Evaluate\n",
        "    avg_precision = trainer.offline_pmf_evaluate(T_precision)\n",
        "\n",
        "    # Append to list\n",
        "    pmf_Ts.append(avg_precision)\n",
        "\n",
        "  # Save data\n",
        "  pmf_Ts = np.array(pmf_Ts)\n",
        "  np.save(output_path + f'avg_precision@{T_precision}_offline_pmf_eval.npy', pmf_Ts)\n",
        "\n",
        "  # Save\n",
        "  sourceFile = open(output_path + f'avg_precision@{T_precision}_offline_pmf_eval.txt', 'w')\n",
        "  print(f'Average Precision@{T_precision} (Eval): {np.mean(pmf_Ts)}', file=sourceFile)\n",
        "  sourceFile.close()\n",
        "\n",
        "# DRR\n",
        "# for T_precision in T_precisions:\n",
        "#   drr_Ts = []\n",
        "#   for i in range(20):\n",
        "#     # Evaluate\n",
        "#     avg_precision = trainer.offline_evaluate(T_precision)\n",
        "\n",
        "#     # Append to list\n",
        "#     drr_Ts.append(avg_precision)\n",
        "\n",
        "#   # Save data\n",
        "#   drr_Ts = np.array(drr_Ts)\n",
        "#   np.save(output_path + f'avg_precision@{T_precision}_offline_eval.npy', drr_Ts)\n",
        "\n",
        "#   # Save\n",
        "#   sourceFile = open(output_path + f'avg_precision@{T_precision}_offline_eval.txt', 'w')\n",
        "#   print(f'Average Precision@{T_precision} (Eval): {np.mean(drr_Ts)}', file=sourceFile)\n",
        "#   sourceFile.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "is3Xr02uaRRT"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'results/241012-14/avg_precision@5_offline_pmf_eval.npy'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pmf_fives \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mavg_precision@5_offline_pmf_eval.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m pmf_tens \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(output_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_precision@10_offline_pmf_eval.npy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m pmf_fifteens \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(output_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_precision@15_offline_pmf_eval.npy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/lib/_npyio_impl.py:459\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    457\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 459\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    460\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'results/241012-14/avg_precision@5_offline_pmf_eval.npy'"
          ]
        }
      ],
      "source": [
        "pmf_fives = np.load(output_path + 'avg_precision@5_offline_pmf_eval.npy')\n",
        "pmf_tens = np.load(output_path + 'avg_precision@10_offline_pmf_eval.npy')\n",
        "pmf_fifteens = np.load(output_path + 'avg_precision@15_offline_pmf_eval.npy')\n",
        "pmf_twenties = np.load(output_path + 'avg_precision@20_offline_pmf_eval.npy')\n",
        "\n",
        "drr_fives = np.load(output_path + 'avg_precision@5_offline_eval.npy')\n",
        "drr_tens = np.load(output_path + 'avg_precision@10_offline_eval.npy')\n",
        "drr_fifteens = np.load(output_path + 'avg_precision@15_offline_eval.npy')\n",
        "drr_twenties = np.load(output_path + 'avg_precision@20_offline_eval.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Oh3MbSc3UL5f"
      },
      "outputs": [],
      "source": [
        "Ts = [5, 10, 15, 20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PXLn-z83LHBs",
        "outputId": "f9a30daf-10be-4ffe-fa77-e134604cd51a"
      },
      "outputs": [],
      "source": [
        "# Online evaluate\n",
        "for T in Ts:\n",
        "  avgs = []\n",
        "  # Change T\n",
        "  config.episode_length = T\n",
        "  for i in range(20):\n",
        "    # Evaluate\n",
        "    avg_reward = trainer.online_evaluate()\n",
        "\n",
        "    # Append data\n",
        "    avgs.append(avg_reward)\n",
        "\n",
        "  # Save data\n",
        "  avgs = np.array(avgs)\n",
        "  np.save(output_path + f'avg_reward@{T}_online_eval.npy', avgs)\n",
        "\n",
        "  # Save\n",
        "  sourceFile = open(output_path + f'avg_reward@{T}_online_eval.txt', 'w')\n",
        "  print(f'Average Reward@{T} (Eval): {np.mean(avgs)}', file=sourceFile)\n",
        "  sourceFile.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "r-juKLJ5fB1-"
      },
      "outputs": [],
      "source": [
        "online_fives = np.load(output_path + 'avg_reward@5_online_eval.npy')\n",
        "online_tens = np.load(output_path + 'avg_reward@10_online_eval.npy')\n",
        "online_fifteens = np.load(output_path + 'avg_reward@15_online_eval.npy')\n",
        "online_twenties = np.load(output_path + 'avg_reward@20_online_eval.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 998
        },
        "id": "ncEjIuCbRBOp",
        "outputId": "d2dea250-3c84-433c-f350-8d0c91cc45b6"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'pmf_fives' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[16], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m   plt\u001b[38;5;241m.\u001b[39msavefig(filename)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Combine data\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m pmf_offline_eval_data \u001b[38;5;241m=\u001b[39m [\u001b[43mpmf_fives\u001b[49m, pmf_tens, pmf_fifteens, pmf_twenties]\n\u001b[1;32m     16\u001b[0m offline_eval_data \u001b[38;5;241m=\u001b[39m [drr_fives, drr_tens, drr_fifteens, drr_twenties]\n\u001b[1;32m     17\u001b[0m online_eval_data \u001b[38;5;241m=\u001b[39m [online_fives, online_tens, online_fifteens, online_twenties]\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pmf_fives' is not defined"
          ]
        }
      ],
      "source": [
        "    # Evaluation @K Graphing\n",
        "\n",
        "    def createEvalPlot(title, ylabel, xlabel, filename, x, y, e, e_x_off, e_y_off):\n",
        "      plt.figure()\n",
        "      plt.errorbar(x, y, yerr=e, fmt='.-', ecolor=\"red\", capsize=3)\n",
        "      plt.title(title)\n",
        "      plt.xlabel(xlabel)\n",
        "      plt.ylabel(ylabel)\n",
        "      plt.xticks(x)\n",
        "      for i, j in zip(x, y):\n",
        "          plt.annotate(str(round(j, 4)), xy=(i+e_x_off, j+e_y_off))\n",
        "      plt.savefig(filename)\n",
        "\n",
        "    # Combine data\n",
        "    pmf_offline_eval_data = [pmf_fives, pmf_tens, pmf_fifteens, pmf_twenties]\n",
        "    offline_eval_data = [drr_fives, drr_tens, drr_fifteens, drr_twenties]\n",
        "    online_eval_data = [online_fives, online_tens, online_fifteens, online_twenties]\n",
        "\n",
        "    # Calculate means and stds for graphing\n",
        "    pmf_offline_means, pmf_offline_stds = [], []\n",
        "    offline_means, offline_stds = [], []\n",
        "    online_means, online_stds = [], []\n",
        "    for d in pmf_offline_eval_data:\n",
        "        pmf_offline_means.append(np.mean(d))\n",
        "        pmf_offline_stds.append(np.std(d))\n",
        "\n",
        "    for d in offline_eval_data:\n",
        "        offline_means.append(np.mean(d))\n",
        "        offline_stds.append(np.std(d))\n",
        "\n",
        "    for d in online_eval_data:\n",
        "        online_means.append(np.mean(d))\n",
        "        online_stds.append(np.std(d))\n",
        "\n",
        "    print(pmf_offline_means)\n",
        "    print(pmf_offline_stds)\n",
        "    print(offline_means)\n",
        "    print(offline_stds)\n",
        "    print(online_means)\n",
        "    print(online_stds)\n",
        "\n",
        "\n",
        "    # Create and save eval plots\n",
        "    createEvalPlot(\"Average Precision @K for Offline PMF Evaluation\\n(500 random users, K recommendations each, 20 times)\",\n",
        "                   \"Average Precision @K\",\n",
        "                   \"K\",\n",
        "                   output_path + \"pmf_offline_eval.png\",\n",
        "                   T_precisions,\n",
        "                   pmf_offline_means,\n",
        "                   pmf_offline_stds,\n",
        "                   0.4,\n",
        "                   0)\n",
        "\n",
        "    createEvalPlot(\"Average Precision @K for Offline DRR Evaluation\\n(500 random users, K recommendations each, 20 times)\",\n",
        "                   \"Average Precision @K\",\n",
        "                   \"K\",\n",
        "                   output_path + \"offline_eval.png\",\n",
        "                   T_precisions,\n",
        "                   offline_means,\n",
        "                   offline_stds,\n",
        "                   0.4,\n",
        "                   0)\n",
        "\n",
        "    createEvalPlot(\n",
        "        \"Average Reward @K for Online DRR Evaluation\\n(20,000 recommendations at each K, 20 times)\",\n",
        "        \"Average Reward @K\",\n",
        "        \"K\",\n",
        "        output_path + \"online_eval.png\",\n",
        "        Ts,\n",
        "        online_means,\n",
        "        online_stds,\n",
        "        0.3,\n",
        "        -0.004)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "train_drr.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "drl-based-recommendation",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
